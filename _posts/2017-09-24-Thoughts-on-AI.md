---
title: Thoughts on AI
layout: post
categories:
  - ZHAW
  - Opinion
---

*The following post is an assignment for the ZHAW course KI1 (Artificial Intelligence), given by [Thilo Stadelmann](http://stdm.github.io) during the autumn semester of 2017.*

*As part of the assignment students have to state their thoughts on AI at the beginning of the course.*

---

Technology is steadily becoming more capable of simulation a human brain, at least from a computation power standpoint. A supercomputer in China has already more than three times the necessary calculation-per-second requirement and in the next ten years they will become more and more common until it is well within reach of anyone that has access to a computer now.

Similarly, science is coming up with new inventions faster than it ever has in the timeline since humans first appeared on the surface of the earth. Early estimates place the creation of an AI that is capable of accomplishing anything a human can in the next 10 to 30 years. The question has evolved from _will we ever_ be able to create such an AGI (Artificial General Intelligence) to **when** will we be able to - in short: It is highly unlikely that our generation will perish from this world without an AI reaching AGI levels.

While all the above is true, there is always a risk when talking about AI: hype. 






---

## Facts and Questions
##### Fact 1
Technological advancements in the recent years have made it possible that the raw calculation power equivalent to that of a human brain will be available to anyone for as low as 1000$ by 2025.

##### Fact 2
When comparing the intelligence of an ant, a chimp and a human, AI (Artificial Intelligence) is slowly closing the gap. While it might look "cute" how it struggles with menial tasks for a human, once AI surpasses human capabilities, understanding its cognitive abilities will be equivalent to teaching an ant about general relativity.

##### Fact 3
When looking at the different types of AI...
* **_ANI_**: **A**rtificial **N**arrow **I**ntelligence, specialised in a single task
* **_AGI_**: **A**rtificial **G**eneral **I**ntelligence, can do anything that a human can
*  **_ASI_**: **A**rtificial **S**uper**i**ntelligence, surpassing even the most gifted human minds

...there is reason for concern. Not only will AI at some point surpass our cognitive abilities, but when it will, we will be able to understand its intelligence as much as an ant can understand about general relativity.

##### Question 1
> Everybody is a genius. But if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid.

While we do not want any AI to end up being a fish that cannot climb a tree, our perception of advancements in the field usually have us compare AI results by human standards. Should we treat AI agents as a _human_ entity and hold it to our standards? Do agents have to replace us or is there a way to use them as enhancements?

##### Question 2
Is human extinction an inevitable outcome of the emergence of any ASI (Artificial Superintelligence) or will the first ASI herald the start of a golden age of immortality?

---

## Sources
[Urban, 2015] Tim Urban, “[The AI Revolution: The Road to Superintelligence](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)”. 2015.

[Ford, Hayes, Glymour, Allen, 2015] Kenneth M. Ford, Patrick J. Hayes, Clark Glymour, James Allen, “[Cognitive Orthoses: Toward Human-Centered AI](https://www.aaai.org/ojs/index.php/aimagazine/article/viewFile/2629/2526)”. 2015.
