---
title: Thoughts on AI
layout: post
categories:
  - ZHAW
  - Opinion
---

*The following post is an assignment for the ZHAW course KI1 (Artificial Intelligence), given by [Thilo Stadelmann](http://stdm.github.io) during the autumn semester of 2017.*

*As part of the assignment students have to state their thoughts on AI at the beginning of the course.*

---

Technology is steadily becoming more capable of simulating a human brain, at least from a computation power standpoint. A supercomputer in China has already more than three times the necessary calculation-per-second requirement and in the next ten years computers with that amount of computation power will become more and more common until anyone can buy the raw performance of a human brain.

Similarly, science is coming up with new inventions faster than it ever has in the history of humanity. Early estimates place the creation of an AI that is capable of accomplishing anything a human can in the next 10 to 30 years. The question has evolved from _will we ever_ be able to create such an AGI (Artificial General Intelligence) to **when** will we be able to - in short: It is unlikely that our generation will perish from this world without an AI reaching AGI levels.

While the above is true, there is always a risk of overselling AI just with the term alone. AI implies a man-made entity capable of reasoning and *intelligent* behaviour. The meaning of the word *intelligence* varies from one person to another, everyone knows instinctively what it means, but defining it with greater detail is not a trivial task.
When the researchers in 1956 at Dartmouth College coined the term *AI*, there was another option of naming it. I strongly believe that with a less *provocative* name the public would not have been as disappointed with the lack of apparent progress that was being made. Even though funding was rare to come by during the "AI winters" that followed, remarkable progress was made in AI and the fields connected to it before, after and even during these winters.

I personally caught myself thinking about AI a lot in the week or so that I spent writing this blog post, culminating in the sudden realization that AI is about *solving complex problems with huge amounts of data and dynamic input* and not about creating an artificial superhuman. Will one eventually lead to the other? Quite possibly so. I do not think it is far fetched to assume an agent with a body which operates on a general algorithm to solve almost anything and learn from its experience will be possible. We might already be there in some way - Alexa, Cortana and Siri might not be an AGI, but I still cannot shake the feeling that all they are missing is the ability to appear as a [hologram](https://i.pinimg.com/originals/6b/82/06/6b820635ce2473a1ba7765f140025e3c.jpg).

Setting aside the whole aspect of *what **is** AI*, in the past few months a new topic has erupted and taken the world by storm: *Will the first ASI be the end of humanity?* While the whole world seems to be split on this question, either thinking we are building our own demise or cautious to build a *friendly and save* AI, Tim Urban has an interesting take on the issue. He argues that any species that ever lived on our planet either went extinct or is still alive, meaning there is one thing that is certain: death ~~*(and taxes)*~~.
Although researchers have made tremendous advances in medicine, it is highly unlikely that we will stumble over a recipe for immortality in the future. AI however might be at the brink of something that will change our lives in ways we cannot imagine. Think of an everyday struggle that the average ant has to deal with in its everyday life. Now try to deal with that issue as a human - all of a sudden, finding food or moving that leaf from A to B is not such a big deal anymore. Similarly, what we humans perceive as an incredibly difficult task might be about as difficult as adding 1+1 together for an ASI. All of a sudden, immortality or at least vast increases in life expectancy and quality of life are to be expected. For this reason alone, I say *[I welcome our new AI overlords](https://www.youtube.com/watch?v=MKx3JlTnHbc)*.

Arguably, it will not be easy to develop an AGI safely and without flaws, but the benefits would be beyond our imagination.

---

## Facts and Questions
##### Fact 1
Technological advancements in the recent years have made it possible that the raw calculation power equivalent to that of a human brain will be available to anyone for as low as 1000$ by 2025.

##### Fact 2
When comparing the intelligence of an ant, a chimp and a human, AI (Artificial Intelligence) is slowly closing the gap. While it might look "cute" how it struggles with menial tasks for a human, once AI surpasses human capabilities, understanding its cognitive abilities will be equivalent to teaching an ant about general relativity.

##### Fact 3
When looking at the different types of AI...
* **_ANI_**: **A**rtificial **N**arrow **I**ntelligence, specialised in a single task
* **_AGI_**: **A**rtificial **G**eneral **I**ntelligence, can do anything that a human can
* **_ASI_**: **A**rtificial **S**uper**i**ntelligence, surpassing even the most gifted human minds

...there is reason for concern. Not only will AI at some point surpass our cognitive abilities, but when it will, we will be able to understand its intelligence as much as an ant can understand about general relativity.

##### Question 1
> Everybody is a genius. But if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid.

While we do not want any AI to end up being a fish that cannot climb a tree, our perception of advancements in the field usually have us compare AI results by human standards. Should we treat AI agents as a _human_ entity and hold it to our standards? Do agents have to replace us or is there a way to use them as enhancements?

##### Question 2
Is human extinction an inevitable outcome of the emergence of any ASI (Artificial Superintelligence) or will the first ASI herald the start of a golden age of immortality?

---

## Sources
[Urban, 2015] Tim Urban, “[The AI Revolution: The Road to Superintelligence](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)”. 2015.

[Ford, Hayes, Glymour, Allen, 2015] Kenneth M. Ford, Patrick J. Hayes, Clark Glymour, James Allen, “[Cognitive Orthoses: Toward Human-Centered AI](https://www.aaai.org/ojs/index.php/aimagazine/article/viewFile/2629/2526)”. 2015.
