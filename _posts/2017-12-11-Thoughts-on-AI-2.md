---
title: "[WIP] Thoughts on AI 2/2"
layout: post
categories:
  - ZHAW
  - Opinion
draft: true
---

*The following post is an assignment for the ZHAW course KI1 (Artificial Intelligence), given by [Thilo Stadelmann](http://stdm.github.io) during the autumn semester of 2017.*

*This assignment is a follow up exercise where each student is given the task to write a second blog post and revisit opinions as well as provide a reply to the [TODO: link first blog post]('http://edualc.github.io/thoughts-on-ai').*

---

A few months ago I ventured into the first artificial intelligence lecture, not really knowing what to expect. I assumed I would be confronted with robots and the need for life insurance. Instead, this semester demonstrated how badly the name was chosen and how much more concise "algorithms for complex computer problems" would have been.

Tim Urban's *[The AI Revolution: The Road to Superintelliengece](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)* painted a very optimistic "the end is nigh-ish" picture with human demise in close proximity. It's writing captures an audience, but how trustworthy is the information given? Recent years have shown that AI programs are capable of solving incredibly complex tasks both faster and better than humans ever could, even though small adjustments to these problems would need a complete overhaul for the AI system that solved it. The question we need to ask ourselves, when evaluating how close we are to the last days on earth, is: 

*Is the sheer amount of functions and the immense complexity of each and every function in such a way that one big AI system could do all those things that our brain already does?* 

- Example: driving in the car, can view signals, stay inside road borders, ... but also realize time of day, weather, people, "personal kinks and issues" like number patterns in license plates ,...

All that being said, I still believe and hope that one day there will be a working artificial *general* intelligence agent. Not from a self-destructive desire or the wish to play god, but because it would mean someone managed to build an AI system that can *teach*. Why is that such a milestone? Well, current AI implementations resolve around pattern finding or "clever" searching all the possible solutions. This has very little to do with intelligence in my opinion. Now if an AI was to teach a human a new concept it would mean the AI actually understood the concept (and by that a vastly more generalized version of a problem). It would 



Teaching




- still think that it is possible to eventually build an AGI
- the AI field excels at very specific tasks, **very** hard to generalize
- broader picture hard to grasp
- comparison to humans: there are always more tasks that go on inside a human brain / living entity (which needs to be simulated as well)
- our brains are wired to think linearly, exponential growth is beyond our senses

---

## Sources
[Brooks, 2017] Brooks Rodney, “[The Seven Deadly Sins of AI Predictions](https://www.technologyreview.com/s/609048/the-seven-deadly-sins-of-ai-predictions/)”. 2017.

[Urban, 2015] Tim Urban, “[The AI Revolution: The Road to Superintelligence](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)”. 2015.
